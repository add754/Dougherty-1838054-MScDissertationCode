{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3a) MSc Project 2019 Aaron Dougherty Word2Vec Models.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["5dinSc783HHe","oBNy1W8DgZBF","8LLZVOyYgmaf","RPSGKHpweDWj","RhNdhmTzjJW4","rlva2WKauLCb"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IEVlUoZFg1fB","colab_type":"text"},"source":["#Initial Downloads and imports"]},{"cell_type":"code","metadata":{"id":"daOKW2oawhZ_","colab_type":"code","outputId":"0da38064-f1f6-4683-8b60-792f16fc71b8","executionInfo":{"status":"ok","timestamp":1567724365857,"user_tz":-60,"elapsed":3401,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","\n","from datetime import datetime\n","from dateutil.parser import parse\n","\n","from sklearn import svm\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle, resample\n","\n","import gensim\n","import warnings\n","warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","from gensim.models.keyedvectors import KeyedVectors\n","from gensim.models import Word2Vec\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.models.phrases import Phrases, Phraser\n","\n","import matplotlib.pyplot as plt\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk import word_tokenize\n","\n","import sys\n","import csv\n","csv.field_size_limit(sys.maxsize)\n","\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Lambda, Input, concatenate\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n","from keras.preprocessing.text import Tokenizer\n","from collections import defaultdict\n","from keras.layers.convolutional import Convolution1D"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.14.0\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"N1mgDLsNjyIo","colab_type":"code","outputId":"8426e8c5-688e-45da-f900-ed5bd6092b15","executionInfo":{"status":"ok","timestamp":1567724384295,"user_tz":-60,"elapsed":21831,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# Mount drive to import necessary files:\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5KCF4GaPL8Dv","colab_type":"code","colab":{}},"source":["# def prepare_text_data(titles, content):\n","#   \"\"\" Method to load in data and prepare final pandas.DataFrame for inputting\n","#       machine learning algorithms\n","\n","#   Parameters\n","#   ----------\n","#   titles : str\n","#       File name of numpy array of title document embedding vectors\n","#   content : str\n","#       File name of numpy array of content document embedding vectors\n","#   \"\"\"\n","#   # file path for main csv file of all text data\n","#   path = '/content/drive/My Drive/Colab Notebooks/csvData/title_content.csv'\n","#   # read in main csv file into pandas.DataFrame\n","#   df = pd.read_csv(path, encoding='ISO-8859-1', engine='python', error_bad_lines=False)\n","#   # file path for sentiment and finance data\n","#   path2 = '/content/drive/My Drive/Colab Notebooks/csvData/sent_fin.csv'\n","#   # read in csv fiel into pandas.DataFrame\n","#   sent_fin = pd.read_csv(path2, encoding='ISO-8859-1', engine='python', error_bad_lines=False)\n","#   # remove useless columns\n","#   sent_fin.drop('Unnamed: 0', axis=1, inplace=True)\n","#   df.drop('Unnamed: 0', axis=1, inplace=True)\n","#   print('initial dataframes loaded')\n","#   # load in document vectors\n","#   titleVecs = np.load(\"/content/drive/My Drive/Colab Notebooks/Word2VecData/\" + titles,\n","#                       allow_pickle=True)\n","#   contentVecs = np.load(\"/content/drive/My Drive/Colab Notebooks/Word2VecData/\" + content,\n","#                       allow_pickle=True)\n","#   print('word embeddings loaded')\n","#   # load document vectors into data frame\n","#   df['title_vectors'] = pd.Series(titleVecs.tolist())\n","#   df['content_vectors'] = pd.Series(contentVecs.tolist())\n","#   print('word embeddings added to dataframe')\n","  \n","#   for index, row in df.iterrows(): # convert vectors to numpy arrays\n","#     row['title_vectors'] = np.array(row['title_vectors'])\n","#     row['content_vectors'] = np.array(row['content_vectors'])\n","#   print('text converted to numpy arrays')\n","#   # find mean document vector per date\n","#   result_df = df.groupby('date')['title_vectors'].apply(np.mean).to_frame('Title')\n","#   result_df2 = df.groupby('date')['content_vectors'].apply(np.mean).to_frame('Content')\n","#   print('mean of document vectors for each date found')\n","#   # recombine data frames created above\n","#   result_df['Content'] = pd.Series(result_df2['Content'])\n","#   result_df = result_df.reset_index().rename(columns={\"date\" : \"Date\"})\n","#   # merge text data with finance and sentiment data\n","#   result_df = result_df.merge(sent_fin, how='inner', on='Date')\n","#   return result_df\n","\n","def prepare_text_data(titles):\n","  \"\"\" Method to load in data and prepare final pandas.DataFrame for inputting\n","      machine learning algorithms\n","\n","  Parameters\n","  ----------\n","  titles : str\n","      File name of numpy array of title document embedding vectors\n","  content : str\n","      File name of numpy array of content document embedding vectors\n","  \"\"\"\n","  # file path for main csv file of all text data\n","  path = '/content/drive/My Drive/Colab Notebooks/MSc Project 2019 Aaron Dougherty csvData/title_content.csv'\n","  # read in main csv file into pandas.DataFrame\n","  df = pd.read_csv(path, encoding='ISO-8859-1', engine='python', error_bad_lines=False)\n","  # file path for sentiment and finance data\n","  path2 = '/content/drive/My Drive/Colab Notebooks/MSc Project 2019 Aaron Dougherty csvData/sent_fin.csv'\n","  # read in csv fiel into pandas.DataFrame\n","  sent_fin = pd.read_csv(path2, encoding='ISO-8859-1', engine='python', error_bad_lines=False)\n","  # remove useless columns\n","  sent_fin.drop('Unnamed: 0', axis=1, inplace=True)\n","  df.drop('content', axis=1, inplace=True)\n","  df.drop('Unnamed: 0', axis=1, inplace=True)\n","  print('initial dataframes loaded')\n","  # load in document vectors\n","  titleVecs = np.load(\"/content/drive/My Drive/Colab Notebooks/MSc Project 2019 Aaron Dougherty Word2VecData/\" + titles,\n","                      allow_pickle=True)\n","  print('word embeddings loaded')\n","  # load document vectors into data frame\n","  df['title_vectors'] = pd.Series(titleVecs.tolist())\n","  print('word embeddings added to dataframe')\n","  \n","  for index, row in df.iterrows(): # convert vectors to numpy arrays\n","    row['title_vectors'] = np.array(row['title_vectors'])\n","  print('text converted to numpy arrays')\n","  # find mean document vector per date\n","  result_df = df.groupby('date')['title_vectors'].apply(np.mean).to_frame('Title')\n","  print('mean of document vectors for each date found')\n","  # recombine data frames created above\n","  result_df = result_df.reset_index().rename(columns={\"date\" : \"Date\"})\n","  # merge text data with finance and sentiment data\n","  result_df = result_df.merge(sent_fin, how='inner', on='Date')\n","  return result_df\n","\n","# def explode_df(df):\n","#   \"\"\" Method to explode document vectors into on column per value for feeding\n","#       into machine learning algorithms\n","\n","#   Parameters\n","#   ----------\n","#   df : pandas.DataFrame\n","#       data frame to expand\n","#   \"\"\"\n","#   df1 = df.iloc[:, 0:3]\n","#   df2 = df.iloc[:, 3:]\n","#   df2['Date'] = df1['Date']\n","#   splitTitle = pd.DataFrame(df1['Title'].tolist())\n","#   splitContent = pd.DataFrame(df1['Content'].tolist())\n","#   splitTitle['Date'] = pd.Series(df1['Date'])\n","#   splitContent['Date'] = pd.Series(df1['Date'])\n","#   final = pd.merge(splitTitle, splitContent, how='inner', on='Date')\n","#   final = final.merge(df2, how='inner', on='Date')\n","#   return final\n","\n","def explode_df(df):\n","  \"\"\" Method to explode document vectors into on column per value for feeding\n","      into machine learning algorithms\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","      data frame to expand\n","  \"\"\"\n","  df1 = df.iloc[:, 0:2]\n","  df2 = df.iloc[:, 2:]\n","  df2['Date'] = df1['Date']\n","  splitTitle = pd.DataFrame(df1['Title'].tolist())\n","  splitTitle['Date'] = pd.Series(df1['Date'])\n","  final = splitTitle.merge(df2, how='inner', on='Date')\n","  return final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQHVlciMVsgp","colab_type":"code","outputId":"4ae786ec-6b8d-415d-dbf8-44b3d8762428","executionInfo":{"status":"ok","timestamp":1567724405768,"user_tz":-60,"elapsed":21465,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["# prepare final data frame\n","df = prepare_text_data('wordvec2_titles_doc3.npy')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["initial dataframes loaded\n","word embeddings loaded\n","word embeddings added to dataframe\n","text converted to numpy arrays\n","mean of document vectors for each date found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IBTmjOJ5kO9f","colab_type":"code","colab":{}},"source":["df = explode_df(df)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sCZAed1he7y","colab_type":"text"},"source":["#Training/Development/Testing Split"]},{"cell_type":"code","metadata":{"id":"VKo9RuxNKmIv","colab_type":"code","colab":{}},"source":["def shuffle_df(df):\n","  \"\"\" Method to shuffle rows of a data frame\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","      Data frame to shuffle\n","  \"\"\"\n","  index = df.index # record data frame indexes\n","  df = shuffle(df) # ScikitLearn's shuffle method\n","  df.index = index # reset indexes\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AZwtviGKsvA","colab_type":"code","outputId":"b523c77e-e561-4637-e347-11c921ad08a9","executionInfo":{"status":"ok","timestamp":1567724408692,"user_tz":-60,"elapsed":1003,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["# split into X and y\n","X = df.iloc[:, 0:-15] # set to -8 to remove financial data and -1 to include; -15 removes sentiment\n","X.drop('Date', axis=1, inplace=True)\n","y = df[['Date', 'Direction']]\n","# split into training, development and testing sets\n","X_train, X_other, y_train, y_other = train_test_split(X, y, test_size=0.2, shuffle=False)\n","X_dev, X_test, y_dev, y_test = train_test_split(X_other, y_other, test_size=0.5, shuffle=False)\n","# remove useless columns\n","y_dev.drop('Date', axis=1, inplace=True)\n","y_test.drop('Date', axis=1, inplace=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  errors=errors)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5dinSc783HHe","colab_type":"text"},"source":["##Dealing with class imbalance:"]},{"cell_type":"code","metadata":{"id":"vThVyFVDBniZ","colab_type":"code","colab":{}},"source":["def recombine(X, y):\n","  \"\"\" Method to recombine the X and y\n","\n","  Parameters\n","  ----------\n","  X : pandas.DataFrame\n","      Data frame containing X variables\n","  y : pandas.DataFrame\n","      Data frame containing y variables\n","  \"\"\"\n","  train = X_train\n","  train['Direction'] = y_train['Direction'] # combine X and y\n","  return train\n","\n","def address_class_imbalance(df, minority_classification, majority_classification,\n","                            minority_target_samples, majority_target_samples):\n","  \"\"\" Method to remove class imbalance within a data set for binary classification\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","      Data frame to check for and remove class imbalances from\n","  minority_classification : int\n","      the minority class\n","  majority_classification : int\n","      the majority class\n","  minority_target_samples: int\n","      number of samples to upsample to\n","  majority_target_samples: int\n","      number of samples to downsample to\n","  \"\"\"\n","  # Split data frame in 2, 1 for each class\n","  minority_class = df[df.Direction == minority_classification]\n","  majority_class = df[df.Direction == majority_classification]\n"," \n","  # down sample majority and up sample minority the desired amount using helper\n","  # methods\n","  downsampled_majority = downsample_majority(majority_class, majority_target_samples)\n","  upsampled_minority = upsample_minority(minority_class, minority_target_samples)\n","  \n","  # combine newly sampled data frames\n","  new_df = upsampled_minority\n","  new_df = new_df.append(downsampled_majority, ignore_index=True)\n","\n","  return new_df\n","\n","# Upsample helper method\n","def upsample_minority(minority_class, target_samples):\n","  \"\"\" Method to up sample the minority class\n","\n","  Parameters\n","  ----------\n","  minority_class : int\n","      the minority class\n","  target_samples: int\n","      number of samples to upsample to\n","  \"\"\"\n","  return resample(minority_class, replace = True, n_samples = target_samples)\n","\n","# Downsample helper method\n","def downsample_majority(majority_class, target_samples):\n","  \"\"\" Method to down sample the majority class\n","\n","  Parameters\n","  ----------\n","  majority_class : int\n","      the majority class\n","  majority_target_samples: int\n","      number of samples to downsample to\n","  \"\"\"\n","  return resample(majority_class, replace = False, n_samples = target_samples)\n","\n","def find_y_mid_point(df):\n","  \"\"\" Method to find the mid-point between to class counts\n","\n","  Parameters\n","  ----------\n","  df : pandas.DataFrame\n","      dataframe to find midpoint in between 2 unbalanced classes\n","  \"\"\"\n","  # count number of rows belonging to each binary class\n","  count_class_0, count_class_1 = df.Direction.value_counts()\n","  # calculate mid-point\n","  mid_point = int(count_class_1 + ((count_class_0 - count_class_1)/2))\n","  return mid_point"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITrtkeeMk2Ga","colab_type":"code","outputId":"81dccf7f-87ea-4c8e-9614-93b4a215b945","executionInfo":{"status":"ok","timestamp":1567724412801,"user_tz":-60,"elapsed":997,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["# rebalance classes using mis point (up and down sample classes equally)\n","train = recombine(X_train, y_train) # recombine training sets\n","target_sample = find_y_mid_point(train) # determine target sample value\n","# up and down sample the classes to remove imbalance\n","train = address_class_imbalance(train, 1, 0, target_sample, target_sample)\n","train = shuffle_df(train) # shuffle the new training set\n","# Split training set back into X and y\n","X_train = train.iloc[:, 0:-1]\n","y_train = train[['Direction']]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PtNDooBjyEVy","colab_type":"code","outputId":"5f7713c2-9072-4f55-986c-02237b70d074","executionInfo":{"status":"ok","timestamp":1567724413508,"user_tz":-60,"elapsed":591,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["minority_class = train[train.Direction == 1]\n","majority_class = train[train.Direction == 0]\n","print(len(minority_class), len(majority_class))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["150 150\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oBNy1W8DgZBF","colab_type":"text"},"source":["#SVM"]},{"cell_type":"markdown","metadata":{"id":"laUZfT77f4s-","colab_type":"text"},"source":["without sentiment or finance"]},{"cell_type":"code","metadata":{"id":"BeHw8L2mf6au","colab_type":"code","outputId":"94f40ce7-5a9e-4e81-a417-72ba6df4b013","executionInfo":{"status":"ok","timestamp":1566077603862,"user_tz":-60,"elapsed":2073,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.58      0.70      0.64        20\n","           1       0.57      0.44      0.50        18\n","\n","    accuracy                           0.58        38\n","   macro avg       0.58      0.57      0.57        38\n","weighted avg       0.58      0.58      0.57        38\n","\n","[[14  6]\n"," [10  8]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"uZPxfhXNqDaL","colab_type":"code","outputId":"f26859a7-9bff-4f42-9227-9eb9854c02a7","executionInfo":{"status":"ok","timestamp":1567724452219,"user_tz":-60,"elapsed":1000,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# Titles + content\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.SVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        16\n","           1       0.58      1.00      0.73        22\n","\n","    accuracy                           0.58        38\n","   macro avg       0.29      0.50      0.37        38\n","weighted avg       0.34      0.58      0.42        38\n","\n","[[ 0 16]\n"," [ 0 22]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6wYTVWw54IJy","colab_type":"code","outputId":"f859131f-8dd0-4e5d-9139-a754918a0f5b","executionInfo":{"status":"ok","timestamp":1567258669608,"user_tz":-60,"elapsed":974,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.74      0.76        23\n","           1       0.62      0.67      0.65        15\n","\n","    accuracy                           0.71        38\n","   macro avg       0.70      0.70      0.70        38\n","weighted avg       0.71      0.71      0.71        38\n","\n","[[17  6]\n"," [ 5 10]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wK712mxZeqef","colab_type":"text"},"source":["without finance data but with sentiment"]},{"cell_type":"code","metadata":{"id":"HEFus1ameb7X","colab_type":"code","outputId":"fafb99c6-b852-464e-d1ac-e8ed20a1a212","executionInfo":{"status":"ok","timestamp":1566077210239,"user_tz":-60,"elapsed":825,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.55      0.60        22\n","           1       0.50      0.62      0.56        16\n","\n","    accuracy                           0.58        38\n","   macro avg       0.58      0.59      0.58        38\n","weighted avg       0.60      0.58      0.58        38\n","\n","[[12 10]\n"," [ 6 10]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"q8j4K2aC4iVi","colab_type":"code","outputId":"19c059af-b334-4b8c-fb5e-9875d3110ad0","executionInfo":{"status":"ok","timestamp":1567258728643,"user_tz":-60,"elapsed":1003,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.70      0.74        23\n","           1       0.61      0.73      0.67        15\n","\n","    accuracy                           0.71        38\n","   macro avg       0.71      0.71      0.71        38\n","weighted avg       0.73      0.71      0.71        38\n","\n","[[16  7]\n"," [ 4 11]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GcP6LN-Yeu8E","colab_type":"text"},"source":["with finance data and sentiment"]},{"cell_type":"code","metadata":{"id":"M7RvImEz6P63","colab_type":"code","outputId":"7535f94d-8f08-41e8-ab6b-7af59e0ecbc9","executionInfo":{"status":"ok","timestamp":1566076642944,"user_tz":-60,"elapsed":852,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Content + titles\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.64      0.70        22\n","           1       0.60      0.75      0.67        16\n","\n","    accuracy                           0.68        38\n","   macro avg       0.69      0.69      0.68        38\n","weighted avg       0.70      0.68      0.69        38\n","\n","[[14  8]\n"," [ 4 12]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UADsCrV14pQc","colab_type":"code","outputId":"3843675c-b03d-4f76-b573-fdab49474e12","executionInfo":{"status":"ok","timestamp":1567258792337,"user_tz":-60,"elapsed":996,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","# SVM_classifier = svm.SVC(kernel='sigmoid')\n","SVM_classifier = svm.LinearSVC()\n","\n","#Train the model using the training sets\n","SVM_classifier.fit(X_train, y_train)\n","\n","#Predict the response for test dataset\n","y_predSVM = SVM_classifier.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predSVM))\n","print(confusion_matrix(y_dev, y_predSVM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.65      0.71        23\n","           1       0.58      0.73      0.65        15\n","\n","    accuracy                           0.68        38\n","   macro avg       0.68      0.69      0.68        38\n","weighted avg       0.71      0.68      0.69        38\n","\n","[[15  8]\n"," [ 4 11]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8LLZVOyYgmaf","colab_type":"text"},"source":["#RF"]},{"cell_type":"markdown","metadata":{"id":"GA04lWv1gGHA","colab_type":"text"},"source":["without finance or sentiment"]},{"cell_type":"code","metadata":{"id":"DoiW8o4agHuy","colab_type":"code","outputId":"88776ecb-c4d8-4539-f8a5-5a814d107787","executionInfo":{"status":"ok","timestamp":1566077652899,"user_tz":-60,"elapsed":1032,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + Content\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.75      0.59        20\n","           1       0.29      0.11      0.16        18\n","\n","    accuracy                           0.45        38\n","   macro avg       0.38      0.43      0.37        38\n","weighted avg       0.39      0.45      0.39        38\n","\n","[[15  5]\n"," [16  2]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YrQ4TNwt4t-D","colab_type":"code","outputId":"da0e0915-f124-4bc8-a73f-ee12dfda432c","executionInfo":{"status":"ok","timestamp":1567258678409,"user_tz":-60,"elapsed":996,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.78      0.69        23\n","           1       0.44      0.27      0.33        15\n","\n","    accuracy                           0.58        38\n","   macro avg       0.53      0.52      0.51        38\n","weighted avg       0.55      0.58      0.55        38\n","\n","[[18  5]\n"," [11  4]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7AKmrOdvfGGK","colab_type":"text"},"source":["without finance but with sentiment"]},{"cell_type":"code","metadata":{"id":"YL6RKPGQfIRF","colab_type":"code","outputId":"849b47be-3979-4ff2-c6f4-6a058bfd20f6","executionInfo":{"status":"ok","timestamp":1566077392117,"user_tz":-60,"elapsed":966,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + Content\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.68      0.64        22\n","           1       0.46      0.38      0.41        16\n","\n","    accuracy                           0.55        38\n","   macro avg       0.53      0.53      0.53        38\n","weighted avg       0.54      0.55      0.54        38\n","\n","[[15  7]\n"," [10  6]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hqgCYxBF48Rd","colab_type":"code","outputId":"16f793df-5538-426e-9b74-33c0221e6fb6","executionInfo":{"status":"ok","timestamp":1567258743531,"user_tz":-60,"elapsed":679,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.87      0.74        23\n","           1       0.57      0.27      0.36        15\n","\n","    accuracy                           0.63        38\n","   macro avg       0.61      0.57      0.55        38\n","weighted avg       0.62      0.63      0.59        38\n","\n","[[20  3]\n"," [11  4]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"jGe2jsqOfD8I","colab_type":"text"},"source":["with finance data and sentiment"]},{"cell_type":"code","metadata":{"id":"CtHxomvjgoDO","colab_type":"code","outputId":"798c425d-2642-4e11-b461-448c08e0833e","executionInfo":{"status":"ok","timestamp":1566076691447,"user_tz":-60,"elapsed":2493,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.64      0.64        22\n","           1       0.50      0.50      0.50        16\n","\n","    accuracy                           0.58        38\n","   macro avg       0.57      0.57      0.57        38\n","weighted avg       0.58      0.58      0.58        38\n","\n","[[14  8]\n"," [ 8  8]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zTi19i7I4-r_","colab_type":"code","outputId":"330d0e9a-3de2-4113-ee7d-44bb77e4706a","executionInfo":{"status":"ok","timestamp":1567258802307,"user_tz":-60,"elapsed":997,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","rndm_fc = RandomForestClassifier()\n","rndm_fc = rndm_fc.fit(X_train, y_train)\n","y_predRF = rndm_fc.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predRF))\n","print(confusion_matrix(y_dev, y_predRF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.70      0.67        23\n","           1       0.46      0.40      0.43        15\n","\n","    accuracy                           0.58        38\n","   macro avg       0.55      0.55      0.55        38\n","weighted avg       0.57      0.58      0.57        38\n","\n","[[16  7]\n"," [ 9  6]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RPSGKHpweDWj","colab_type":"text"},"source":["#GBM"]},{"cell_type":"markdown","metadata":{"id":"3kWZXYRJgQrb","colab_type":"text"},"source":["without finance or sentiment"]},{"cell_type":"code","metadata":{"id":"4tnYLx7zgNdG","colab_type":"code","outputId":"6382343b-5ef7-49fe-a70a-f027fb17f004","executionInfo":{"status":"ok","timestamp":1566077692871,"user_tz":-60,"elapsed":2109,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.70      0.61        20\n","           1       0.50      0.33      0.40        18\n","\n","    accuracy                           0.53        38\n","   macro avg       0.52      0.52      0.50        38\n","weighted avg       0.52      0.53      0.51        38\n","\n","[[14  6]\n"," [12  6]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"APw9Hr9z5Fwv","colab_type":"code","outputId":"8ecab1b7-a880-4add-870d-27265c8cb789","executionInfo":{"status":"ok","timestamp":1567258687757,"user_tz":-60,"elapsed":1261,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["#Titles only\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.83      0.75        23\n","           1       0.60      0.40      0.48        15\n","\n","    accuracy                           0.66        38\n","   macro avg       0.64      0.61      0.61        38\n","weighted avg       0.65      0.66      0.64        38\n","\n","[[19  4]\n"," [ 9  6]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ds_KkZQpfUgs","colab_type":"text"},"source":["without finance but with sentiment"]},{"cell_type":"code","metadata":{"id":"J0GSRSUDfXLg","colab_type":"code","outputId":"b80e3987-49ba-4482-ab88-ec59364b03e6","executionInfo":{"status":"ok","timestamp":1566077456470,"user_tz":-60,"elapsed":2502,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.64      0.64        22\n","           1       0.50      0.50      0.50        16\n","\n","    accuracy                           0.58        38\n","   macro avg       0.57      0.57      0.57        38\n","weighted avg       0.58      0.58      0.58        38\n","\n","[[14  8]\n"," [ 8  8]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V545gvsq5M4m","colab_type":"code","outputId":"49d47d82-dc1e-43bc-c051-a1853e711cb9","executionInfo":{"status":"ok","timestamp":1567258761358,"user_tz":-60,"elapsed":2001,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.83      0.79        23\n","           1       0.69      0.60      0.64        15\n","\n","    accuracy                           0.74        38\n","   macro avg       0.73      0.71      0.72        38\n","weighted avg       0.73      0.74      0.73        38\n","\n","[[19  4]\n"," [ 6  9]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TcyaLEiVfSjD","colab_type":"text"},"source":["with finance and sentiment"]},{"cell_type":"code","metadata":{"id":"8l5scB3yeCVI","colab_type":"code","outputId":"b7ca46f4-8b0f-4eca-da92-2d58f3ce30ce","executionInfo":{"status":"ok","timestamp":1566076722461,"user_tz":-60,"elapsed":2667,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles + content\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.55      0.55      0.55        22\n","           1       0.38      0.38      0.38        16\n","\n","    accuracy                           0.47        38\n","   macro avg       0.46      0.46      0.46        38\n","weighted avg       0.47      0.47      0.47        38\n","\n","[[12 10]\n"," [10  6]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sg3Nplpf5POG","colab_type":"code","outputId":"0d77e689-f20d-4c70-ef1c-f85595da2888","executionInfo":{"status":"ok","timestamp":1567258811022,"user_tz":-60,"elapsed":1254,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Titles only\n","GBM = GradientBoostingClassifier()\n","GBM = GBM.fit(X_train, y_train)\n","y_predGBM = GBM.predict(X_dev)\n","\n","print(classification_report(y_dev, y_predGBM))\n","print(confusion_matrix(y_dev, y_predGBM))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.83      0.79        23\n","           1       0.69      0.60      0.64        15\n","\n","    accuracy                           0.74        38\n","   macro avg       0.73      0.71      0.72        38\n","weighted avg       0.73      0.74      0.73        38\n","\n","[[19  4]\n"," [ 6  9]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RhNdhmTzjJW4","colab_type":"text"},"source":["#Neural Network Prep"]},{"cell_type":"code","metadata":{"id":"fcwzd3atjNoM","colab_type":"code","colab":{}},"source":["# define documents:\n","def create_xtext(x_df, col):\n","  \"\"\" Method to format data for the nerual network\n","\n","  Parameters\n","  ----------\n","  X_df : pandas.DataFrame\n","      X values\n","  col:  str\n","      relevant columns\n","  \"\"\"\n","  arr = []\n","  for index, row in x_df.iterrows():\n","    arr.append(x_df[col].loc[index]) # add text data to array row by row\n","  return np.array(arr)\n","  \n","# create list of concatenated vectors\n","def create_xtext_concat(x_df):\n","  \"\"\" Method to format data for the nerual network\n","\n","  Parameters\n","  ----------\n","  X_df : pandas.DataFrame\n","      X values\n","  col:  str\n","      relevant columns\n","  \"\"\"\n","  arr = []\n","  for index, row in x_df.iterrows():\n","    # concatenate title and content vectors on each row\n","    concatenated_vector = np.concatenate((x_df['Title'].loc[index], x_df['Content'].loc[index]),\n","                                         axis=None)\n","    arr.append(concatenated_vector) # add text data to array row by row\n","  return np.array(arr)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtIdqfm9j9hY","colab_type":"code","colab":{}},"source":["# transform titles and content into array format\n","train_titles = create_xtext(X_train, 'Title')\n","train_content = create_xtext(X_train, 'Content')\n","\n","dev_titles = create_xtext(X_dev, 'Title')\n","dev_content = create_xtext(X_dev, 'Content')\n","\n","test_titles = create_xtext(X_test, 'Title')\n","test_content = create_xtext(X_test, 'Content')\n","\n","# prepare y variables\n","train_labels = y_train['Direction'].tolist()\n","dev_labels = y_dev['Direction'].tolist()\n","test_labels = y_test['Direction'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lN5ZTxdZkGGC","colab_type":"code","colab":{}},"source":["# convert y variables into one hot vector encodings for categorical crossentropy\n","y_train__binary_matrix = to_categorical(y_train['Direction'], num_classes = 2)\n","y_dev__binary_matrix = to_categorical(y_dev['Direction'], num_classes = 2)\n","y_test__binary_matrix = to_categorical(y_test['Direction'], num_classes = 2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2ONyssC4TDz","colab_type":"text"},"source":["##Concatenate variables for sequential MLP model version"]},{"cell_type":"code","metadata":{"id":"8mVuNAny4YTV","colab_type":"code","colab":{}},"source":["# transform titles and content into array format\n","training = create_xtext_concat(X_train)\n","\n","development = create_xtext_concat(X_dev)\n","\n","testing = create_xtext_concat(X_test)\n","\n","# prepare y variables\n","train_labels = y_train['Direction'].tolist()\n","dev_labels = y_dev['Direction'].tolist()\n","test_labels = y_test['Direction'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Uoi3b5G54tk","colab_type":"code","outputId":"faee099d-3e67-4e0f-b69c-d10d8203116a","executionInfo":{"status":"ok","timestamp":1566084406052,"user_tz":-60,"elapsed":456,"user":{"displayName":"Aaron Dougherty","photoUrl":"","userId":"09194565351303205340"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_titles.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 600)"]},"metadata":{"tags":[]},"execution_count":278}]},{"cell_type":"markdown","metadata":{"id":"rlva2WKauLCb","colab_type":"text"},"source":["#MLP"]},{"cell_type":"markdown","metadata":{"id":"8VOwwYt7okh8","colab_type":"text"},"source":["##Version1"]},{"cell_type":"code","metadata":{"id":"lD3TaQ4muJ5k","colab_type":"code","colab":{}},"source":["nb_classes = 2\n","\n","# Inputs\n","titles_input = Input(shape=(300,), name='titles_input')\n","content_input = Input(shape=(300,), name='content_input')\n"," \n","# the first branch operates on the first input\n","titles = Dense(2000, activation=\"relu\")(titles_input)\n","titles = Dropout(0.5)(titles)\n","titles = Dense(1280, activation=\"relu\")(titles)\n","titles = Model(inputs=titles_input, outputs=titles)\n"," \n","# the second branch opreates on the second input\n","content = Dense(2000, activation=\"relu\")(content_input)\n","content = Dropout(0.5)(content)\n","content = Dense(1280, activation=\"relu\")(content)\n","content = Model(inputs=content_input, outputs=content)\n"," \n","# combine the output of the two branches\n","concat = concatenate([titles.output, content.output])\n"," \n","# apply a FC layer and then a regression prediction on the\n","# combined outputs\n","fc = Dense(1000, activation=\"relu\")(concat)\n","fc = Dropout(0.5)(fc)\n","fc = Dense(500, activation=\"relu\")(fc)\n","fc = Dropout(0.1)(fc)\n","fc = Dense(2, activation=\"sigmoid\")(fc)\n"," \n","# our model will accept the inputs of the two branches and\n","# then output a single value\n","model = Model(inputs=[titles.input, content.input], outputs=fc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RMiEvLIqQDi","colab_type":"code","colab":{}},"source":["print(model.summary())\n","\n","opt = Adam(lr=0.0001, clipnorm=1., decay=1e-6, amsgrad=True) ## decay=1e-6, \n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bk9X9bJ7sAtO","colab_type":"code","colab":{}},"source":["model.fit([train_titles, train_content], y_train__binary_matrix, batch_size = 5, epochs=15, verbose=1, validation_split=0.15)\n","\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbaePdwTxka7","colab_type":"code","colab":{}},"source":["print(\"Generating test predictions...\")\n","y_predMLP = model.predict([test_titles, test_content], verbose=1)\n","y_pred_bool = np.argmax(y_predMLP, axis=1)\n","print(classification_report(y_test, y_pred_bool))\n","print(confusion_matrix(y_test, y_pred_bool))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTo5Una2ohQn","colab_type":"text"},"source":["##Version 2"]},{"cell_type":"code","metadata":{"id":"p7GtY5eV9aFY","colab_type":"code","colab":{}},"source":["nb_classes = 2\n","\n","# Deep Dumb MLP (DDMLP):\n","model = Sequential() # creates linear DNN model which consists of a linear\n","                     # stack of layers\n","# first number value is the fixed batch size of the layer\n","model.add(Dense(1000, input_shape=(600,))) # 2D layer specifies input shape\n","model.add(Activation('relu')) # activation function of layer\n","# Applies dropout to input\n","# randomly setting a fraction/rate of input units to 0 at each update during\n","# training, which helps prevent overfitting\n","model.add(Dropout(0.4))\n","model.add(Dense(500))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(nb_classes)) # final binary classification layer\n","model.add(Activation('softmax'))\n","\n","# configure learning process\n","# Contains optimizer function, loss function and a list of metrics\n","print(model.summary())\n","\n","opt = Adam(lr=0.0001, clipnorm=1., decay=1e-6, amsgrad=True) ## decay=1e-6, \n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","print(\"training...\")\n","history = model.fit(training, y_train__binary_matrix, batch_size = 12, epochs = 20, verbose=1, validation_split=0.15)\n","\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wq76Fy82m1a4","colab_type":"code","colab":{}},"source":["y_predMLP2 = model.predict(testing, verbose=1)\n","y_pred_bool2 = np.argmax(y_predMLP2, axis=1)\n","\n","acc = accuracy_score(test_labels, preds)\n","print('Accuracy: %' acc)\n","print(classification_report(test_labels, y_pred_bool2))\n","print(confusion_matrix(test_labels, y_pred_bool2))"],"execution_count":0,"outputs":[]}]}